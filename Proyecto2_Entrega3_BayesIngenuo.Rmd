---
title: "Proyecto 2. Entrega 3. Bayes Ingenuo"
author: 
  - "Pablo Daniel Barillas Moreno, Carné No. 22193"
  - "Mathew Cordero Aquino, Carné No. 22982"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
date: "2025-03-14"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-3_MineriaDeDatos_Grupo-1-.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 3 de minería de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-3_MineriaDeDatos_Grupo-1-.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extraídos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir automáticamente las variables categóricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspección inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estadístico de las variables numéricas y una descripción general de las categóricas.

```{r}
  train_data <- read.csv("house_prices_data/train.csv", stringsAsFactors = FALSE)
  test_data <- read.csv("house_prices_data/test.csv", stringsAsFactors = FALSE)
  
  head(train_data)   # Muestra las primeras filas
  str(train_data)    # Muestra la estructura del dataset
  summary(train_data) # Resumen estadístico
```
### 1. Elabore un modelo de regresión usando bayes ingenuo (naive bayes), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las hojas anteriores para que los modelos sean comparables. 

```{r}
# Cargar librerías necesarias
library(e1071)  # Para Naive Bayes
library(caret)  # Para particionar los datos y evaluar el modelo
library(dplyr)  # Para manipulación de datos
library(ggplot2) # Para visualización

# 1. Cargar conjuntos de datos asegurando que sean los mismos que en entregas anteriores
train_set <- read.csv("train_set.csv", stringsAsFactors = TRUE)
test_set <- read.csv("test_set.csv", stringsAsFactors = TRUE)

# 2. Eliminar la columna Id si existe
if ("Id" %in% colnames(train_set)) {
  train_set <- train_set %>% select(-Id)
}
if ("Id" %in% colnames(test_set)) {
  test_set <- test_set %>% select(-Id)
}

# 3. Verificar que SalePrice está presente
if (!"SalePrice" %in% colnames(train_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset de entrenamiento.")
}
if (!"SalePrice" %in% colnames(test_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset de prueba.")
}

# 4. Manejar valores faltantes en SalePrice
train_set <- train_set %>% filter(!is.na(SalePrice))
test_set <- test_set %>% filter(!is.na(SalePrice))

# 5. Aplicar transformación logarítmica a SalePrice para mejorar distribución
train_set$LogSalePrice <- log(train_set$SalePrice)
test_set$LogSalePrice <- log(test_set$SalePrice)

# 6. Convertir SalePrice en una variable categórica para clasificación
quantiles <- quantile(train_set$SalePrice, probs = c(0.33, 0.66), na.rm = TRUE)

train_set$Categoria <- cut(train_set$SalePrice,
                           breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                           labels = c("Económica", "Intermedia", "Cara"))

test_set$Categoria <- cut(test_set$SalePrice,
                          breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                          labels = c("Económica", "Intermedia", "Cara"))

# Convertir `Categoria` a factor
train_set$Categoria <- as.factor(train_set$Categoria)
test_set$Categoria <- as.factor(test_set$Categoria)

# 7. Asegurar que las variables categóricas tengan los mismos niveles en train y test
categorical_vars <- names(train_set)[sapply(train_set, is.factor)]
for (var in categorical_vars) {
  test_set[[var]] <- factor(test_set[[var]], levels = levels(train_set[[var]]))
}

# 8. MODELO DE NAIVE BAYES PARA REGRESIÓN (LogSalePrice)
set.seed(42)
modelo_nb_reg <- naiveBayes(LogSalePrice ~ ., data = train_set)

# 9. Predicción en el conjunto de prueba
predicciones_reg <- predict(modelo_nb_reg, newdata = test_set)

# 10. Evaluación del modelo de regresión: Calcular el Error Cuadrático Medio (MSE) y su conversión
if (!is.numeric(predicciones_reg)) {
  predicciones_reg <- as.numeric(as.character(predicciones_reg))
}
mse_nb <- mean((test_set$LogSalePrice - predicciones_reg)^2, na.rm = TRUE)
rmse_nb <- sqrt(mse_nb)  # Raíz cuadrada del MSE

# Convertir RMSE de la escala logarítmica a dólares
error_dolares <- exp(rmse_nb)

cat("Error cuadrático medio (MSE) del modelo Naive Bayes (Regresión):", mse_nb, "\n")
cat("Raíz del error cuadrático medio (RMSE):", rmse_nb, "\n")
cat("Error estimado en dólares:", error_dolares, "\n")

# 11. MODELO DE NAIVE BAYES PARA CLASIFICACIÓN (Categoría)
set.seed(42)
modelo_nb_class <- naiveBayes(Categoria ~ ., data = train_set)

# 12. Predicción en el conjunto de prueba
predicciones_class <- predict(modelo_nb_class, newdata = test_set)

# 13. Evaluación del modelo de clasificación: Matriz de confusión y F1-Score
conf_matrix <- confusionMatrix(predicciones_class, test_set$Categoria)
print(conf_matrix)

# Calcular F1-Score por clase
f1_scores <- conf_matrix$byClass[, "F1"]
cat("F1-Score para cada categoría:\n")
print(f1_scores)

# 14. Gráfico de comparación de valores reales vs predichos (Regresión)
ggplot(data.frame(Real = test_set$LogSalePrice, Predicho = predicciones_reg), aes(x = Real, y = Predicho)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
  labs(title = "Predicción del Modelo Naive Bayes vs Valores Reales",
       x = "Precio Real (Log)",
       y = "Precio Predicho (Log)") +
  theme_minimal()

# 15. Gráfico de comparación de predicciones vs valores reales (Clasificación)
ggplot(data.frame(Real = test_set$Categoria, Predicho = predicciones_class), aes(x = Real, fill = Predicho)) +
  geom_bar(position = "dodge", color = "black", alpha = 0.8) +
  labs(title = "Comparación de Predicciones del Modelo Naive Bayes",
       x = "Categoría Real",
       y = "Cantidad de Casas") +
  theme_minimal() +
  theme(legend.position = "top", legend.title = element_blank()) +
  scale_fill_manual(values = c("Económica" = "#E74C3C", "Intermedia" = "#27AE60", "Cara" = "#3498DB"))
```
**Análisis y Conclusiones del Modelo Naive Bayes**

**1.1.  Evaluación del Modelo de Regresión**

El modelo de Naive Bayes fue utilizado para predecir los precios de las casas en su forma logarítmica. Para evaluar su desempeño, analizamos el Error Cuadrático Medio (MSE), la Raíz del Error Cuadrático Medio (RMSE) y el error estimado en dólares.

- MSE (Error Cuadrático Medio) = 0.05044311
El MSE mide la diferencia promedio cuadrática entre los valores reales y los valores predichos. Un valor bajo indica que el modelo tiene un error reducido. En este caso, el valor 0.0504 sugiere que la diferencia entre los valores reales y predichos es pequeña.

- RMSE (Raíz del Error Cuadrático Medio) = 0.2245954
La raíz cuadrada del MSE nos permite interpretar el error en la misma escala que los valores de salida (logaritmo de los precios). Un RMSE de 0.2246 indica que, en promedio, los valores predichos se desvían por esta cantidad del valor real en la escala logarítmica.

- Error estimado en dólares = 1.251816
Para convertir el RMSE en una interpretación más útil, revertimos la transformación logarítmica usando la función exponencial. Esto nos indica que, en promedio, el error en la predicción es aproximadamente 1.25 veces el valor real del precio de la casa.

Interpretación: Esto significa que, en promedio, el modelo puede estar subestimando o sobrestimando los precios en un factor de 1.25, lo cual en términos prácticos indica que el modelo tiene un margen de error del 25% en los valores predichos.

**1.2. Evaluación del Modelo de Clasificación**

El modelo de Naive Bayes también fue usado para clasificar las casas en tres categorías: Económica, Intermedia y Cara. Para evaluar su desempeño, analizamos la matriz de confusión, la precisión global, la estadística Kappa y las métricas por clase.

**1.2.1. Matriz de Confusión**

La matriz de confusión nos muestra cuántas casas fueron correctamente clasificadas y cuántas fueron incorrectamente asignadas a otra categoría.
 
|    **Categoría**     |  **Económica (Real)**   |**Intermedia (Real)**|**Cara (Real)** |
|----------------------|-------------------------|---------------------|----------------|
|**Económica (Pred.)** |           89            |           31        |        4       |   
|**Intermedia (Pred.)**|            5            |           64        |        5       |
|   **Cara (Pred.)**   |            0            |           12        |       81       |

Interpretación:

- La mayoría de las casas fueron correctamente clasificadas en su categoría real.

- Errores significativos en la categoría "Intermedia", donde 31 casas fueron clasificadas erróneamente como Económicas y 12 como Caras.

- La categoría "Cara" tuvo la menor cantidad de errores, lo que sugiere que el modelo es mejor identificando casas de alto valor.

**1.2.2. Precisión Global y Estadística Kappa**

✔ Precisión Global = 80.41%
 
- La precisión global indica que el modelo clasifica correctamente el 80.41% de las casas en su categoría correcta.

✔ Kappa = 0.7077

- La estadística Kappa mide qué tan bien funciona el modelo en comparación con una clasificación aleatoria. Un valor de 0.70 indica un buen nivel de acuerdo, pero deja margen para mejorar.

**1.3. Evaluación por Clase**

Para analizar cómo se desempeñó el modelo en cada categoría, evaluamos la sensibilidad, especificidad, valor predictivo positivo (PPV) y el F1-Score.

**1.3.1. Sensibilidad (Recall)**

Indica qué tan bien el modelo detecta correctamente cada clase.

- Económica: 94.68% → El modelo detectó casi todas las casas económicas correctamente.

- Intermedia: 59.81% → Se desempeñó peor en esta categoría, indicando que muchas casas intermedias fueron clasificadas incorrectamente.

- Cara: 90.00% → La detección de casas caras fue bastante alta.

Conclusión: El modelo tiende a confundir casas intermedias con económicas o caras, lo cual sugiere que podría mejorar en la clasificación de casas en este rango medio.

**1.3.2. Especificidad**

Indica qué tan bien el modelo evita clasificar incorrectamente una clase.

- Económica: 82.23%

- Intermedia: 94.57%

- Cara: 94.03%

Interpretación:

- El modelo distingue bien las casas intermedias y caras, pero tiene más problemas separando económicas e intermedias.

- Es menos preciso cuando clasifica casas económicas, ya que algunas de ellas terminan en la categoría intermedia.

**1.3.3. F1-Score (Balance entre precisión y recall)**

- Económica: 0.8165

- Intermedia: 0.7071

- Cara: 0.8852

Interpretación:

- El mejor desempeño está en la categoría Cara (0.88), lo que indica que el modelo maneja bien los precios altos.

- El peor desempeño es en la categoría Intermedia (0.70), lo que confirma que la clasificación en este rango es el mayor desafío.

**1.4. Desempeño del Modelo de Regresión**

- El MSE de 0.0504 y RMSE de 0.2246 indican un buen nivel de ajuste, aunque hay una variabilidad en la predicción.

- El error estimado en dólares (1.25 veces) significa que el modelo puede sobreestimar o subestimar los precios de las casas en aproximadamente un 25%.

- Este margen de error es aceptable para una estimación rápida, pero podría ser problemático en decisiones comerciales donde la precisión es clave.

**1.4.1. Desempeño del Modelo de Clasificación**

- Precisión global del 80.41% es un buen resultado para un modelo de clasificación en 3 categorías.

- El modelo funciona bien en casas económicas y caras, pero tiene problemas con casas intermedias.

- La clase intermedia es la más difícil de clasificar, lo que sugiere que puede haber una superposición en las características de estas casas con las otras categorías.

**Análisis de las Gráficas del Inciso 1: Modelo de Naive Bayes para Regresión y Clasificación**

**Gráfico 1: Predicción del Modelo Naive Bayes vs Valores Reales (Regresión)**

Este gráfico muestra la relación entre los valores reales de LogSalePrice (precio de venta en escala logarítmica) y los valores predichos por el modelo de Naive Bayes en la tarea de regresión. Se puede observar:

- **Distribución Alineada:** La mayoría de los puntos se encuentran cercanos a la línea roja punteada, que representa la igualdad entre el valor real y el predicho. Esto sugiere que el modelo logra capturar una relación significativa entre las variables explicativas y el precio de venta.

- **Mayor Dispersión en Valores Bajos:** Se observa que para precios bajos (aproximadamente menores a 11 en escala logarítmica), hay mayor dispersión de los puntos, lo que indica que el modelo no es tan preciso en estos casos.

- **Menos Errores en Valores Altos:** Para precios altos (mayores a 12), la predicción parece ajustarse mejor a la tendencia general, aunque hay algunos valores dispersos fuera de la línea esperada.

En general, la regresión con Naive Bayes muestra un buen desempeño, con una tendencia clara de ajuste, pero con errores más notorios en la predicción de valores bajos.

**Gráfico 2: Comparación de Predicciones del Modelo Naive Bayes (Clasificación)**

Este gráfico representa la cantidad de casas en cada categoría (Económica, Intermedia y Cara) según las predicciones del modelo de Naive Bayes comparadas con los valores reales.

- **Sobrerrepresentación de Económica:** Se observa que el modelo predice más casas en la categoría Económica de las que realmente pertenecen a esta clase. Esto sugiere que el modelo tiende a clasificar algunas casas intermedias como económicas, lo que se alinea con la sensibilidad alta (0.9468) pero una precisión más baja (0.7177) en esta clase.

- **Dificultad en la Clase Intermedia:** La clase Intermedia muestra más errores en la predicción. Varias casas de esta categoría han sido clasificadas como Económica o Cara, lo que indica que esta clase es la más difícil de identificar correctamente para el modelo. Esto concuerda con la baja sensibilidad (0.5981) y la precisión media (0.8649) de esta categoría.

- **Buena Predicción para Cara:** La categoría Cara es la que presenta mejor desempeño después de Económica, con pocas casas clasificadas erróneamente en Intermedia o Económica, lo que se refleja en su alta sensibilidad (0.9000) y precisión aceptable (0.8710).

El modelo de Naive Bayes funciona bien para clasificar casas Económicas y Caras, pero tiene más dificultades en la categoría Intermedia, lo cual es un resultado esperable ya que esta categoría puede solaparse con las otras dos.

**Conclusión General**

**Regresión:**

- La predicción de precios sigue bien la tendencia general, con errores menores en valores altos y mayor dispersión en valores bajos.

- El modelo logra un MSE de 0.0504, lo que indica un error moderado pero aceptable.

- La conversión a error en dólares mostró que, en promedio, la diferencia entre el valor real y el predicho es de aproximadamente 1.25 dólares, lo cual es un margen de error bastante bajo en el contexto del mercado inmobiliario.

**Clasificación:**

- El modelo tiene un accuracy de 80.41%, con un buen desempeño en Económica y Cara, pero con problemas en Intermedia.

- La clase Intermedia es la más difícil de predecir, probablemente debido a la cercanía de precios con las otras categorías.

- El F1-Score es alto en Económica (0.8165) y en Cara (0.8852), mientras que en Intermedia es más bajo (0.7071), lo que refleja que el modelo tiene más problemas en esta categoría.

### 2. Analice los resultados del modelo de regresión usando bayes ingenuo. ¿Qué tan bien le fue prediciendo? Utilice las métricas correctas.

**Análisis del Modelo de Regresión Usando Naive Bayes**

Para evaluar el modelo de regresión, revisamos las siguientes métricas obtenidas en el inciso 1:

- Error cuadrático medio (MSE): 0.05044311

- Raíz del error cuadrático medio (RMSE): 0.2245954

- Error estimado en dólares: 1.251816

Estas métricas nos permiten evaluar la calidad de la predicción de SalePrice en su escala logarítmica.

**2.1. Interpretación de las Métricas**

1. El MSE (0.05044311) mide el error promedio al cuadrado. Un valor más bajo indica que el modelo está haciendo predicciones más cercanas a los valores reales.

2. El RMSE (0.2246) es la raíz cuadrada del MSE y nos da una idea del error promedio en las mismas unidades que la variable objetivo. Como estamos trabajando con log(SalePrice), esta desviación puede ser interpretada como un error de aproximadamente ±0.22 en la escala logarítmica.

3. El error estimado en dólares ($1.25 dólares aprox.) se obtiene al quitar la transformación logarítmica, lo que nos da una idea del margen de error del modelo en términos del precio real de las casas.

**2.2. Análisis de la Gráfica de Dispersión**

En la gráfica de predicción del modelo Naive Bayes vs valores reales, observamos que los puntos se alinean bien con la línea de referencia (línea roja punteada). Sin embargo:

- Se pueden notar algunas desviaciones en valores bajos y altos de SalePrice, lo cual es esperable dado que Naive Bayes no es un modelo óptimo para regresión debido a su suposición de independencia condicional.

- Hay casos donde el modelo sobreestima o subestima el precio de las casas, aunque en general sigue la tendencia correcta.

**2.3. Limitaciones del Modelo**

- Naive Bayes no es un modelo diseñado para regresión, ya que su base probabilística lo hace más adecuado para clasificación.

- La suposición de independencia condicional entre las variables predictoras puede hacer que no capture bien relaciones complejas en los datos.

- El error de 1.25 dólares en promedio es bajo, pero para precios de casas más altos esto podría ser significativo.

**2.4. Conclusión**

1. El modelo Naive Bayes para regresión logra capturar la tendencia general de SalePrice, aunque con ciertas desviaciones.

2. El RMSE de 0.2246 y el error estimado en dólares de $1.25 indican que el modelo tiene un desempeño aceptable, aunque no óptimo.

3. El modelo muestra una buena alineación con la línea de referencia en la gráfica de dispersión, pero algunas predicciones presentan variaciones, especialmente en valores extremos.

4. Dado que Naive Bayes asume independencia condicional entre las variables predictoras, su capacidad para modelar relaciones complejas es limitada.

5. En términos prácticos, el modelo puede ser útil para obtener una estimación general del precio de las casas, pero probablemente no sea la mejor opción en comparación con otros métodos más avanzados como la regresión lineal o los árboles de decisión.

### 3. Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las entregas pasadas. ¿Cuál funcionó mejor? 

**Comparación de Modelos de Regresión: Naive Bayes vs. Regresión Lineal vs. Árbol de Decisión**

Para determinar cuál modelo funcionó mejor en la predicción del precio de las casas, analizamos las métricas obtenidas en cada caso, incluyendo el Error Cuadrático Medio (MSE) y la capacidad de generalización en el conjunto de prueba.

**3.1. Modelo de Regresión Naive Bayes**

Error Cuadrático Medio (MSE): 0.05044311

Raíz del Error Cuadrático Medio (RMSE): 0.2245954

Error estimado en dólares: 1.251816

**3.2. Resultados Numéricos de los Modelos Evaluados**

|            **Modelo**             |**MSE en Entrenamiento**|**MSE en Prueba**     |**Raíz del MSE (RMSE)**|**Error Estimado en Dólares**|
|-----------------------------------|------------------------|----------------------|-----------------------|-----------------------------|
|**Regresión Lineal (Ridge)**       |       8.74 × 10^8      |      1.02 × 10^9     |        31,953.1       |          1,678.64           |
|**IÁrbol de Decisión (MaxDepth=5)**|       1.29 × 10^9      |      1.65 × 10^9     |        40,623.5       |          2,135.46           |
|   **Naive Bayes (Regresión)**     |           ---          | 0.05 (log SalePrice) | 0.224 (log SalePrice) |           1,251.81          |

**3.3. Análisis Comparativo**

**3.3.1. Precisión y Generalización de los Modelos**

- **Regresión Lineal (Ridge)** tiene el MSE más bajo en prueba, lo que indica que logra hacer predicciones más precisas y con menor error en datos nuevos.

- **Árbol de Decisión** presenta un MSE mucho mayor en la prueba que en el entrenamiento, lo que indica sobreajuste. El modelo aprende demasiado bien los datos de entrenamiento, pero pierde precisión al predecir datos nuevos.

- **Naive Bayes** (Regresión) tiene un error más bajo en términos de escala logarítmica, pero hay que considerar que esta métrica no es directamente comparable con Ridge y Árbol de Decisión sin deshacer la transformación logarítmica.

**3.3.2. Robustez del Modelo**

- **Regresión Lineal (Ridge)** es más estable, ya que usa regularización para evitar sobreajuste y proporciona predicciones consistentes.

- **Árbol de Decisión** es más susceptible al ruido en los datos, ya que puede generar reglas demasiado específicas en el conjunto de entrenamiento, afectando su capacidad de generalización.

- **Naive Bayes (Regresión)** funciona bien con datos de alta dimensionalidad, pero su supuesto de independencia de variables puede limitar su precisión en problemas más complejos.

**3.3.3. Interpretabilidad**

- **Árbol de Decisión** es el más interpretable, ya que permite visualizar cómo se toman las decisiones de predicción basadas en divisiones de variables.

- **Regresión Lineal** es menos interpretable pero más precisa, ya que los coeficientes de las variables explican cómo afectan el precio.

- **Naive Bayes** no es directamente interpretable en términos de predicción continua, ya que trabaja mejor en problemas de clasificación.

**3.4. Comparación de la Clasificación (Categorías: Económica, Intermedia, Cara)**

Además de la predicción numérica del precio, evaluamos el desempeño en la clasificación de casas en Económicas, Intermedias y Caras.

|            **Modelo**             |**Accuracy**|**F1 Económica**|**F1 Intermedia**|**F1 Cara**|
|-----------------------------------|------------|----------------|-----------------|-----------|
|**Árbol de Decisión**              |   0.7698   |     0.7982     |      0.6477     |  0.8524   |
|**Naive Bayes (Clasificación)**    |   0.7698   |     0.8165     |      0.7071     |  0.8852   |

**3.5. Análisis**

- Naive Bayes tiene una mejor precisión global (80.41%) en comparación con el Árbol de Decisión (76.98%).

- F1-Score es mejor en todas las categorías para Naive Bayes, indicando que clasifica mejor las casas en sus categorías de precio.

- El Árbol de Decisión tiene más errores en la categoría "Intermedia", con un F1-Score de 0.6477, mientras que Naive Bayes logra 0.7071.

**3.6. Conclusión: ¿Cuál Modelo Funcionó Mejor?**

**3.6.1. Mejor Modelo para Predicción de Precio Numérico**

✔ Regresión Lineal (Ridge) es el mejor modelo para predecir el precio exacto de una casa.

- Tiene el menor MSE y RMSE, lo que indica mayor precisión.

- Es más estable y no sufre de sobreajuste como el Árbol de Decisión.

**3.6.2. Mejor Modelo para Clasificación**

✔ Naive Bayes es el mejor modelo para clasificar casas en Económicas, Intermedias y Caras.

- Tiene mayor precisión y F1-Score en todas las clases.

- Maneja mejor la variabilidad de los datos.

**3.6.3. Árbol de Decisión: ¿Útil o No?**
✔ Árbol de Decisión sigue siendo útil para entender qué variables afectan el precio, pero no es la mejor opción para predecir.

- Puede ser una buena herramienta exploratoria para identificar patrones en los datos.

- Sin embargo, tiene problemas de sobreajuste y menor precisión en predicciones.

**3.6.4. Consideraciones Finales**

Si el objetivo es hacer predicciones precisas del precio de una casa, la Regresión Lineal (Ridge) es la mejor opción.

Si el objetivo es clasificar casas en categorías de precio, Naive Bayes supera al Árbol de Decisión en precisión.

El Árbol de Decisión sigue siendo útil para interpretar los datos, pero su precisión es inferior en ambas tareas.

### 4. Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta. 

```{r}
# Cargar librerías necesarias
library(e1071)  # Para Naive Bayes
library(caret)  # Para particionar los datos y evaluar el modelo
library(dplyr)  # Para manipulación de datos
library(ggplot2) # Para visualización

# 1. Cargar conjuntos de datos asegurando que sean los mismos que en entregas anteriores
train_set <- read.csv("train_set.csv", stringsAsFactors = TRUE)
test_set <- read.csv("test_set.csv", stringsAsFactors = TRUE)

# 2. Eliminar la columna Id si existe
if ("Id" %in% colnames(train_set)) {
  train_set <- train_set %>% select(-Id)
}
if ("Id" %in% colnames(test_set)) {
  test_set <- test_set %>% select(-Id)
}

# 3. Verificar que SalePrice está presente
if (!"SalePrice" %in% colnames(train_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset de entrenamiento.")
}
if (!"SalePrice" %in% colnames(test_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset de prueba.")
}

# 4. Manejar valores faltantes en SalePrice
train_set <- train_set %>% filter(!is.na(SalePrice))
test_set <- test_set %>% filter(!is.na(SalePrice))

# 5. Convertir SalePrice en una variable categórica para clasificación
quantiles <- quantile(train_set$SalePrice, probs = c(0.33, 0.66), na.rm = TRUE)

train_set$Categoria <- cut(train_set$SalePrice,
                           breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                           labels = c("Económica", "Intermedia", "Cara"))

test_set$Categoria <- cut(test_set$SalePrice,
                          breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                          labels = c("Económica", "Intermedia", "Cara"))

# Convertir `Categoria` a factor
train_set$Categoria <- as.factor(train_set$Categoria)
test_set$Categoria <- as.factor(test_set$Categoria)

# 6. Asegurar que las variables categóricas tengan los mismos niveles en train y test
categorical_vars <- names(train_set)[sapply(train_set, is.factor)]
for (var in categorical_vars) {
  test_set[[var]] <- factor(test_set[[var]], levels = levels(train_set[[var]]))
}

# 7. MODELO DE NAIVE BAYES PARA CLASIFICACIÓN (Categoría)
set.seed(42)
modelo_nb_class <- naiveBayes(Categoria ~ ., data = train_set)

# 8. Predicción en el conjunto de prueba
predicciones_class <- predict(modelo_nb_class, newdata = test_set)

# 9. Evaluación del modelo de clasificación: Matriz de confusión y F1-Score
conf_matrix <- confusionMatrix(predicciones_class, test_set$Categoria)
print(conf_matrix)

# Calcular F1-Score por clase
f1_scores <- conf_matrix$byClass[, "F1"]
cat("F1-Score para cada categoría:\n")
print(f1_scores)

# 10. Gráfico de comparación de predicciones vs valores reales (Clasificación)
ggplot(data.frame(Real = test_set$Categoria, Predicho = predicciones_class), aes(x = Real, fill = Predicho)) +
  geom_bar(position = "dodge", color = "black", alpha = 0.8) +
  labs(title = "Comparación de Predicciones del Modelo Naive Bayes",
       x = "Categoría Real",
       y = "Cantidad de Casas") +
  theme_minimal() +
  theme(legend.position = "top", legend.title = element_blank()) +
  scale_fill_manual(values = c("Económica" = "#E74C3C", "Intermedia" = "#27AE60", "Cara" = "#3498DB"))
```
**4.1. Evaluación General del Modelo**

El modelo Naive Bayes se utilizó para clasificar casas en tres categorías según su precio: Económica, Intermedia y Cara.

**Precisión Global (Accuracy): 80.41%**

- Indica que el modelo clasifica correctamente el 80.41% de las casas en el conjunto de prueba.

- Este es un resultado bastante sólido para un modelo de clasificación basado en Naive Bayes, que asume independencia entre las variables predictoras.

**Intervalo de Confianza del 95%: (75.38%, 84.81%)**

- Indica que si se repitieran múltiples veces los experimentos, la precisión del modelo estaría en este rango en el 95% de los casos.

**Índice Kappa (0.7077)**

- Este valor mide el grado de acuerdo entre las predicciones del modelo y la realidad, teniendo en cuenta la posibilidad de clasificación aleatoria.

- 0.70 – 0.80 se considera un buen nivel de concordancia, lo que refuerza la solidez del modelo.

**McNemar’s Test p-valor: 1.124e-05**

- Indica que hay diferencias significativas entre las tasas de error de clasificación.

- Sugiere que el modelo presenta algunos sesgos en la predicción de ciertas clases, particularmente en la categoría Intermedia.

**4.2. Evaluación de la Matriz de Confusión**

La matriz de confusión nos da un desglose detallado de los aciertos y errores en la clasificación.

|                         |**Económica (Real)** |**Intermedia (Real)**|**Cara (Real)**|
|-------------------------|---------------------|---------------------|---------------|
|**Económica (Predicha)**	|          89	        |           31	      |        4      |
|**Intermedia (Predicha)**|   	     5	        |           64	      |        5      |
|**Cara (Predicha)**	    |          0	        |           12	      |       81      |

**Observaciones clave:**

**1. Clase Económica:**

- Se clasificaron correctamente 89 casas como económicas.

- 31 casas que en realidad eran intermedias fueron clasificadas erróneamente como económicas.

- 4 casas caras fueron mal clasificadas como económicas.

**2. Clase Intermedia:**

- Se identificaron correctamente 64 casas intermedias.

- 5 casas económicas fueron clasificadas erróneamente como intermedias.

- 5 casas caras también fueron clasificadas erróneamente como intermedias.

**3.Clase Cara:**

- Se identificaron correctamente 81 casas caras.

- 12 casas intermedias fueron clasificadas erróneamente como caras.

- No hubo errores en clasificar casas económicas como caras.

**Errores más significativos:**

- El mayor problema ocurre con las casas intermedias, ya que 31 de ellas fueron clasificadas como económicas y 12 como caras.

- En contraste, las casas caras y económicas tienen menos errores de clasificación.

**4.3. Análisis de Sensibilidad, Especificidad y F1-Score**

|     **Métrica**             |**Económica**|**Intermedia**|**Cara** |
|-----------------------------|-------------|--------------|---------|
|**Sensibilidad (Recall)**	  |    94.68%   |  	59.81%     |	90.00% |
|**Especificidad**            |    82.23%	  |    94.57%    |	94.03% |
|**Precisión Positiva (PPV)** |	  71.77%    |	  86.49%     |	87.10% |
|**Neg Precision Value (NPV)**|	  97.01%	  |    80.18%    |	95.45% |
|**F1-Score**                 |  	0.8165    |  	0.7072	   | 0.8852  |

**Interpretación de cada métrica:**

**1. Sensibilidad (Recall)**

- Mide la proporción de casos correctamente identificados.

- Económica (94.68%) y Cara (90.00%) tienen valores altos, lo que indica que el modelo tiene una buena capacidad para identificar correctamente estas clases.

- Intermedia (59.81%) tiene la sensibilidad más baja, lo que indica que muchas casas intermedias fueron mal clasificadas.

**2. Especificidad**

- Mide la capacidad del modelo para evitar clasificaciones erróneas.

- Intermedia (94.57%) y Cara (94.03%) tienen valores altos, lo que significa que el modelo no suele confundir otras clases con estas.

- Económica (82.23%) es la que tiene más errores al predecir otras clases como económicas.

**3. F1-Score**

Equilibra precisión y sensibilidad.
Cara (0.8852) tiene el mejor desempeño, seguido de Económica (0.8165).
Intermedia (0.7072) tiene el peor desempeño, confirmando que el modelo tiene más problemas clasificando esta categoría.

**4.4. Análisis de la Gráfica**

**Gráfico de comparación de predicciones vs valores reales**

En el gráfico de barras, se observa claramente que:

- Las casas económicas son las que mejor se predicen, con muy pocos errores en comparación con las intermedias.

- Las casas intermedias presentan el mayor desbalance, con errores en ambas direcciones:

Clasificadas como económicas en gran cantidad.
Algunas clasificadas como caras, lo cual sugiere que ciertas características pueden estar causando confusión en el modelo.

- Las casas caras están bien diferenciadas, con muy pocos errores.

**Conclusión General**

- El modelo de clasificación basado en Naive Bayes tiene un rendimiento aceptable (80.41% de precisión), pero con margen de mejora.

- Predice con alta precisión las casas económicas y caras, pero tiene dificultades con las casas intermedias.

- Las métricas sugieren que la mayor fuente de error es la confusión entre casas intermedias y económicas.

- Para mejorar este modelo se podría considerar aumentar la cantidad de datos, usar técnicas de selección de características o emplear modelos más avanzados como Random Forest o SVM.

### 5. Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para predecir y clasificar. 

```{r}
# Cargar librerías necesarias
library(e1071)  # Para Naive Bayes
library(caret)  # Para evaluación de modelos
library(dplyr)  # Para manipulación de datos
library(ggplot2) # Para visualización

# 1. Cargar conjuntos de datos asegurando que sean los mismos que en entregas anteriores
train_set <- read.csv("train_set.csv", stringsAsFactors = TRUE)
test_set <- read.csv("test_set.csv", stringsAsFactors = TRUE)

# 2. Eliminar la columna Id si existe
if ("Id" %in% colnames(train_set)) {
  train_set <- train_set %>% select(-Id)
}
if ("Id" %in% colnames(test_set)) {
  test_set <- test_set %>% select(-Id)
}

# 3. Verificar que SalePrice está presente
if (!"SalePrice" %in% colnames(train_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset de entrenamiento.")
}
if (!"SalePrice" %in% colnames(test_set)) {
  stop("Error: La variable 'SalePrice' no está en el dataset de prueba.")
}

# 4. Manejar valores faltantes en SalePrice
train_set <- train_set %>% filter(!is.na(SalePrice))
test_set <- test_set %>% filter(!is.na(SalePrice))

# 5. Aplicar transformación logarítmica a SalePrice para mejorar la distribución
train_set$LogSalePrice <- log(train_set$SalePrice)
test_set$LogSalePrice <- log(test_set$SalePrice)

# 6. Convertir SalePrice en una variable categórica para clasificación
quantiles <- quantile(train_set$SalePrice, probs = c(0.33, 0.66), na.rm = TRUE)

train_set$Categoria <- cut(train_set$SalePrice,
                           breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                           labels = c("Económica", "Intermedia", "Cara"))

test_set$Categoria <- cut(test_set$SalePrice,
                          breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
                          labels = c("Económica", "Intermedia", "Cara"))

# Convertir `Categoria` a factor
train_set$Categoria <- as.factor(train_set$Categoria)
test_set$Categoria <- as.factor(test_set$Categoria)

# 7. Asegurar que las variables categóricas tengan los mismos niveles en train y test
categorical_vars <- names(train_set)[sapply(train_set, is.factor)]
for (var in categorical_vars) {
  test_set[[var]] <- factor(test_set[[var]], levels = levels(train_set[[var]]))
}

# ---- MODELO NAIVE BAYES PARA REGRESIÓN ----
set.seed(42)
modelo_nb_reg <- naiveBayes(LogSalePrice ~ ., data = train_set)

# Predicción en el conjunto de prueba
predicciones_reg <- predict(modelo_nb_reg, newdata = test_set)

# Evaluación del modelo de regresión: MSE, RMSE y conversión a dólares
if (!is.numeric(predicciones_reg)) {
  predicciones_reg <- as.numeric(as.character(predicciones_reg))
}

mse_nb <- mean((test_set$LogSalePrice - predicciones_reg)^2, na.rm = TRUE)
rmse_nb <- sqrt(mse_nb)
error_dolares <- exp(rmse_nb)

# Imprimir resultados de regresión
cat("\nResultados del modelo de Regresión Naive Bayes:\n")
cat("Error cuadrático medio (MSE):", mse_nb, "\n")
cat("Raíz del error cuadrático medio (RMSE):", rmse_nb, "\n")
cat("Error estimado en dólares:", error_dolares, "\n")

# ---- MODELO NAIVE BAYES PARA CLASIFICACIÓN ----
set.seed(42)
modelo_nb_class <- naiveBayes(Categoria ~ ., data = train_set)

# Predicción en el conjunto de prueba
predicciones_class <- predict(modelo_nb_class, newdata = test_set)

# Evaluación del modelo de clasificación: Matriz de confusión, Accuracy, Kappa y F1-Score
conf_matrix <- confusionMatrix(predicciones_class, test_set$Categoria)

# Imprimir matriz de confusión y métricas
print(conf_matrix)

accuracy <- conf_matrix$overall["Accuracy"]
kappa <- conf_matrix$overall["Kappa"]
f1_scores <- conf_matrix$byClass[, "F1"]

cat("\nResultados del modelo de Clasificación Naive Bayes:\n")
cat("Precisión global (Accuracy):", accuracy, "\n")
cat("Índice Kappa:", kappa, "\n")
cat("F1-Score por categoría:\n")
print(f1_scores)

# ---- GRÁFICOS DE RESULTADOS ----
# Gráfico de comparación de valores reales vs predichos (Regresión)
ggplot(data.frame(Real = test_set$LogSalePrice, Predicho = predicciones_reg), aes(x = Real, y = Predicho)) +
  geom_point(alpha = 0.5, color = "blue") +
  geom_abline(slope = 1, intercept = 0, col = "red", linetype = "dashed") +
  labs(title = "Predicción del Modelo Naive Bayes vs Valores Reales",
       x = "Precio Real (Log)",
       y = "Precio Predicho (Log)") +
  theme_minimal()

# Gráfico de comparación de predicciones vs valores reales (Clasificación)
ggplot(data.frame(Real = test_set$Categoria, Predicho = predicciones_class), aes(x = Real, fill = Predicho)) +
  geom_bar(position = "dodge", color = "black", alpha = 0.8) +
  labs(title = "Comparación de Predicciones del Modelo Naive Bayes",
       x = "Categoría Real",
       y = "Cantidad de Casas") +
  theme_minimal() +
  theme(legend.position = "top", legend.title = element_blank()) +
  scale_fill_manual(values = c("Económica" = "#E74C3C", "Intermedia" = "#27AE60", "Cara" = "#3498DB"))

```
**Análisis del Modelo de Regresión Naive Bayes**

**5.1 Evaluación del Desempeño**

**1. Error Cuadrático Medio (MSE): 0.05044311**

- El MSE mide el error promedio al cuadrado de las predicciones con respecto a los valores reales en la escala logarítmica. Un valor bajo indica que el modelo tiene una precisión aceptable al predecir los precios de las casas.

**2. Raíz del Error Cuadrático Medio (RMSE): 0.2245954**

- El RMSE representa la desviación estándar del error de predicción en la escala logarítmica. Su bajo valor indica que la dispersión de los errores es relativamente pequeña.

**3. Error estimado en dólares: 1.251816**

- Este valor representa la estimación del error de predicción después de convertir el RMSE de la escala logarítmica a dólares. Un error tan bajo sugiere que el modelo está prediciendo los precios con gran precisión.

**5.2 Interpretación de la Gráfica de Regresión**

- La gráfica de dispersión entre los valores reales y predichos muestra una alineación adecuada a lo largo de la línea diagonal de referencia (línea roja discontinua).

- Aunque hay una ligera dispersión en los valores más bajos y más altos de los precios, la mayoría de los puntos siguen una tendencia consistente, lo que indica que el modelo logra capturar bien la estructura de los datos.

- Algunos valores atípicos en el rango inferior sugieren que el modelo tiene dificultades con ciertas propiedades de menor precio, lo cual puede deberse a la falta de suficientes muestras en esa categoría.

**5.3 Análisis del Modelo de Clasificación Naive Bayes**

**Evaluación del Desempeño**

**1. Precisión Global (Accuracy): 0.8041 (80.41%)**

- Indica que el modelo clasificó correctamente el 80.41% de las casas en sus respectivas categorías de precio. Esta es una precisión bastante aceptable para un modelo de clasificación basado en Naive Bayes.

**2. Índice Kappa: 0.7077**

- Mide el grado de acuerdo entre las predicciones y las categorías reales ajustando la probabilidad de clasificación correcta por azar. Un valor cercano a 1 indica un acuerdo alto, por lo que este resultado refuerza la confianza en el modelo.





**F1-Score por Categoría:**

- Económica: 0.8165

- Intermedia: 0.7072

- Cara: 0.8852

- El F1-Score es una métrica combinada de precisión y sensibilidad. El modelo predice mejor las categorías de casas económicas y caras, pero tiene dificultades con la clase intermedia.

**Interpretación de la Gráfica de Clasificación**

- Se observa que las casas económicas (en rojo) están bien predichas, con pocas confusiones.

- Las casas intermedias (en verde) presentan más errores, con algunas siendo clasificadas como económicas o caras.

- Las casas caras (en azul) son bien identificadas con algunas excepciones.

- La distribución de los errores indica que el modelo tiende a sobreestimar o subestimar los precios en ciertos casos, pero mantiene una precisión aceptable.

**5.4 Conclusiones Generales**

**1. Regresión Naive Bayes:**

- Tiene un error bajo (MSE y RMSE), lo que indica que las predicciones del precio logarítmico son bastante precisas.

- Se observa una ligera dispersión en los valores extremos (muy bajos o muy altos), pero en general, el modelo sigue la tendencia de los datos reales.

- La conversión del error a dólares muestra que la diferencia media en la predicción del precio es de aproximadamente $1.25, lo cual es un error extremadamente bajo.

**2. Clasificación Naive Bayes:**

- El modelo logra una precisión del 80.41%, con mejor rendimiento en la predicción de casas económicas y caras, mientras que las casas intermedias tienen más errores de clasificación.

- El índice Kappa de 0.7077 indica que el modelo es confiable y tiene un buen acuerdo entre predicciones y valores reales.

- La matriz de confusión muestra que la mayoría de los errores ocurren en la clasificación de casas intermedias.

**3. Eficiencia General del Algoritmo:**

- Para regresión, el modelo funciona bien al predecir precios, con una dispersión baja en los errores.

- Para clasificación, el modelo es efectivo pero tiene margen de mejora en la categoría intermedia.

- Conclusión final: El modelo de Naive Bayes es eficiente en ambas tareas, aunque su desempeño en clasificación es más inconsistente en la categoría intermedia.

Si se busca mejorar la clasificación, se podrían probar técnicas como:

- Ajuste de hiperparámetros en Naive Bayes.

- Uso de técnicas de ingeniería de características para capturar mejor la relación entre las variables.

- Ensamble con otros modelos como árboles de decisión o modelos de regresión logística.

En general, los modelos aplicados con el conjunto de prueba muestran que Naive Bayes es un método efectivo tanto para regresión como clasificación, con un desempeño particularmente fuerte en la predicción de precios en la escala logarítmica.

### 6. Haga un análisis de la eficiencia del modelo de clasificación usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores. 

```{r}
conf_matrix <- confusionMatrix(predicciones_class, test_set$Categoria)

# Imprimir matriz de confusión y métricas
print(conf_matrix)
conf_df <- as.data.frame(conf_matrix$table)

# Graficar la matriz de confusión
ggplot(conf_df, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white", size = 5) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(title = "Matriz de Confusión",
       x = "Clase Real",
       y = "Predicción") +
  theme_minimal()
```

#### Analisis de Matriz de correccion

**Clases del Modelo**

**Clase Económica:** Sensibilidad (0.9468) y Precisión Positiva (0.7177)

- Se predicen correctamente la mayoría de las casas económicas, aunque algunas se confunden con la categoría Intermedia.

**Clase Intermedia:** Sensibilidad (0.5981) y Precisión Positiva (0.8649)

- Es la categoría con mayor confusión, lo que sugiere que algunas casas intermedias se clasifican erróneamente como económicas o caras.

**Clase Cara:** Sensibilidad (0.9000) y Precisión Positiva (0.8710)

- Se predicen correctamente la mayoría de las casas caras, aunque algunas se clasifican como intermedias.


**Errores Cometidos**

Podemos ver que el modelo se esta equivocando mas en clasificar el precio de las casas intermedias, de hecho es el que mas mal le ha ido, pero a diferencia de las otras clasificaciones, en razon y proporcion es donde menos se ha equivacado en clasificar, de hecho se equivoco mas en clasificar economicas que en intermedias y en caras. 

Se observa que se llego a equivocar mas en clasificar economicas siendo de 0.717 la sensibilidad en detectar casas economicas. Muy posiblemente porque se observa que llego a tener errores al confundir casas economicas y casas intermedias. 

Debido a que existen muchos mas factores en determinar si una casa es economica e intermedia que una cara, esto debido a la distribucion desbalanceada, debido a que existe un sesgo hacia valores de casas economicos y caros. 

Aun asi en comparacion a otros modelos se ha visto que ha sido mas eficiente en la clasificacion que tiene. 


### 7. Analice el modelo. ¿Cree que pueda estar sobreajustado? 

```{r}

```


### 8. Haga un modelo usando validación cruzada, compare los resultados de este con los del modelo anterior. ¿Cuál funcionó mejor? 

```{r}

```


### 9. Tanto para los modelos de regresión como de clasificación, pruebe con varios valores de los hiperparámetros, use el mejor modelo del tuneo, ¿Mejoraron los modelos? Explique 

```{r}

```


### 10.	Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar? 

```{r}

```

